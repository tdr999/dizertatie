{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5i3N-weKP6-",
        "papermill": {
          "duration": 0.022866,
          "end_time": "2021-02-18T10:06:03.865074",
          "exception": false,
          "start_time": "2021-02-18T10:06:03.842208",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/tanishqgautam/Drone-Image-Semantic-Segmentation/blob/main/semantic-segmentation-pytorch.ipynb"
      ],
      "metadata": {
        "id": "5JZ5S-7ciZnz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch #installam bibliotecile pe colab\n",
        "!pip install -U albumentations\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0P8vjDPisFZ",
        "outputId": "0d32eda1-a4b9-4819-bf56-eb851c863de6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.9/dist-packages (0.3.2)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (4.65.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (8.4.0)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: timm==0.6.12 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.6.12)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.9/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (0.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.0.4)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (4.7.0.72)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.2.28)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:03.918990Z",
          "iopub.status.busy": "2021-02-18T10:06:03.918243Z",
          "iopub.status.idle": "2021-02-18T10:06:26.911381Z",
          "shell.execute_reply": "2021-02-18T10:06:26.910479Z"
        },
        "id": "kFSYoYRqJSfB",
        "papermill": {
          "duration": 23.025453,
          "end_time": "2021-02-18T10:06:26.911588",
          "exception": false,
          "start_time": "2021-02-18T10:06:03.886135",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd9bcfb-60f5-44ab-9812-212c4e6e7ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation-models-pytorch in /usr/local/lib/python3.9/dist-packages (0.3.2)\n",
            "Requirement already satisfied: timm==0.6.12 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.6.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (4.65.0)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.7.1)\n",
            "Requirement already satisfied: pretrainedmodels==0.7.4 in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (0.7.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation-models-pytorch) (8.4.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.9/dist-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (0.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (4.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.9/dist-packages (1.5.1)\n",
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms as T\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install torchsummary\n",
        "\n",
        "from torchsummary import summary\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_HWVOdhJSfP",
        "papermill": {
          "duration": 0.026783,
          "end_time": "2021-02-18T10:06:26.966143",
          "exception": false,
          "start_time": "2021-02-18T10:06:26.939360",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:27.026658Z",
          "iopub.status.busy": "2021-02-18T10:06:27.024925Z",
          "iopub.status.idle": "2021-02-18T10:06:27.027303Z",
          "shell.execute_reply": "2021-02-18T10:06:27.027707Z"
        },
        "papermill": {
          "duration": 0.033799,
          "end_time": "2021-02-18T10:06:27.027862",
          "exception": false,
          "start_time": "2021-02-18T10:06:26.994063",
          "status": "completed"
        },
        "tags": [],
        "id": "Q6BZc2nxiXfU"
      },
      "outputs": [],
      "source": [
        "# IMAGE_PATH = '../input/semantic-drone-dataset/dataset/semantic_drone_dataset/original_images/'\n",
        "# MASK_PATH = '../input/semantic-drone-dataset/dataset/semantic_drone_dataset/label_images_semantic/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:27.086824Z",
          "iopub.status.busy": "2021-02-18T10:06:27.086238Z",
          "iopub.status.idle": "2021-02-18T10:06:27.211796Z",
          "shell.execute_reply": "2021-02-18T10:06:27.211315Z"
        },
        "id": "gmPIy2ZFJSfQ",
        "papermill": {
          "duration": 0.157328,
          "end_time": "2021-02-18T10:06:27.211938",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.054610",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# n_classes = 23 \n",
        "\n",
        "# def create_df():\n",
        "#     name = []\n",
        "#     for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
        "#         for filename in filenames:\n",
        "#             name.append(filename.split('.')[0])\n",
        "    \n",
        "#     return pd.DataFrame({'id': name}, index = np.arange(0, len(name)))\n",
        "\n",
        "# df = create_df()\n",
        "# print('Total Images: ', len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:27.279329Z",
          "iopub.status.busy": "2021-02-18T10:06:27.278464Z",
          "iopub.status.idle": "2021-02-18T10:06:27.284966Z",
          "shell.execute_reply": "2021-02-18T10:06:27.284346Z"
        },
        "papermill": {
          "duration": 0.045372,
          "end_time": "2021-02-18T10:06:27.285120",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.239748",
          "status": "completed"
        },
        "tags": [],
        "id": "OFaQDASMiXfW"
      },
      "outputs": [],
      "source": [
        "# #split data\n",
        "# X_trainval, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\n",
        "# X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=19)\n",
        "\n",
        "# print('Train Size   : ', len(X_train))\n",
        "# print('Val Size     : ', len(X_val))\n",
        "# print('Test Size    : ', len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:27.351823Z",
          "iopub.status.busy": "2021-02-18T10:06:27.351238Z",
          "iopub.status.idle": "2021-02-18T10:06:31.594465Z",
          "shell.execute_reply": "2021-02-18T10:06:31.594948Z"
        },
        "id": "-uXF6vetJSff",
        "papermill": {
          "duration": 4.280771,
          "end_time": "2021-02-18T10:06:31.595115",
          "exception": false,
          "start_time": "2021-02-18T10:06:27.314344",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# img = Image.open(IMAGE_PATH + df['id'][100] + '.jpg')\n",
        "# mask = Image.open(MASK_PATH + df['id'][100] + '.png')\n",
        "# print('Image Size', np.asarray(img).shape)\n",
        "# print('Mask Size', np.asarray(mask).shape)\n",
        "\n",
        "\n",
        "# plt.imshow(img)\n",
        "# plt.imshow(mask, alpha=0.6)\n",
        "# plt.title('Picture with Mask Appplied')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/MyDrive/date_dizertatie')\n",
        "base_path = '/content/gdrive/MyDrive/date_dizertatie'\n",
        "\n",
        "\n",
        "#pregatim cuda\n",
        "print(\"Numar cudauri\" + str(torch.cuda.device_count()))\n",
        "print(\"Nume placa video \" + str(torch.cuda.get_device_name(0)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL6URXGdj8KV",
        "outputId": "354dc09d-be6d-4ae1-91a9-f2397e7970a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numar cudauri1\n",
            "Nume placa video NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_dir = os.path.join(base_path, 'train_graz/x')\n",
        "y_train_dir = os.path.join(base_path, 'train_graz/y')\n",
        "\n",
        "x_val_dir = os.path.join(base_path, 'valid_graz/x')\n",
        "y_val_dir = os.path.join(base_path, 'valid_graz/y')\n",
        "\n",
        "x_test_dir = os.path.join(base_path, 'test_graz/x')\n",
        "y_test_dir = os.path.join(base_path, 'test_graz/y')"
      ],
      "metadata": {
        "id": "j9Wrsz9bkFTw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkjFEoe7JSfo",
        "papermill": {
          "duration": 0.030107,
          "end_time": "2021-02-18T10:06:31.656378",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.626271",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:31.731486Z",
          "iopub.status.busy": "2021-02-18T10:06:31.729694Z",
          "iopub.status.idle": "2021-02-18T10:06:31.732068Z",
          "shell.execute_reply": "2021-02-18T10:06:31.732468Z"
        },
        "id": "yne-vteuJSfp",
        "papermill": {
          "duration": 0.045449,
          "end_time": "2021-02-18T10:06:31.732603",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.687154",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "class DroneDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, img_path, mask_path, mean, std, transform=None, patch=False):\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.transform = transform\n",
        "        self.patches = patch\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "        self.ids = sorted(os.listdir(img_path))\n",
        "        self.images_fps = [os.path.join(img_path, image_id) for image_id in self.ids]\n",
        "        self.mask_ids = [i.replace(\"jpg\", \"png\") for i in self.ids]#originalele sunt jpg dar mastile png\n",
        "        self.masks_fps = [os.path.join(mask_path, mask_id) for mask_id in self.mask_ids]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.img_path))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img = cv2.imread(self.images_fps[idx])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks_fps[idx], cv2.IMREAD_GRAYSCALE)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            aug = self.transform(image=img, mask=mask)\n",
        "            img = Image.fromarray(aug['image'])\n",
        "            mask = aug['mask']\n",
        "        \n",
        "        if self.transform is None:\n",
        "            img = Image.fromarray(img)\n",
        "        \n",
        "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
        "        img = t(img)\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "        \n",
        "        if self.patches:\n",
        "            img, mask = self.tiles(img, mask)\n",
        "            \n",
        "        return img, mask\n",
        "    \n",
        "    def tiles(self, img, mask):\n",
        "\n",
        "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768) \n",
        "        img_patches  = img_patches.contiguous().view(3,-1, 512, 768) \n",
        "        img_patches = img_patches.permute(1,0,2,3)\n",
        "        \n",
        "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
        "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
        "        \n",
        "        return img_patches, mask_patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:31.800770Z",
          "iopub.status.busy": "2021-02-18T10:06:31.800210Z",
          "iopub.status.idle": "2021-02-18T10:06:31.804278Z",
          "shell.execute_reply": "2021-02-18T10:06:31.803849Z"
        },
        "id": "CCL93_giJSft",
        "papermill": {
          "duration": 0.041706,
          "end_time": "2021-02-18T10:06:31.804390",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.762684",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "t_train = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(), A.VerticalFlip(), \n",
        "                     A.GridDistortion(p=0.2), A.RandomBrightnessContrast((0,0.5),(0,0.5)),\n",
        "                     A.GaussNoise()])\n",
        "\n",
        "t_val = A.Compose([A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST), A.HorizontalFlip(),\n",
        "                   A.GridDistortion(p=0.2)])\n",
        "\n",
        "#datasets\n",
        "train_set = DroneDataset(x_train_dir, y_train_dir, mean, std, t_train, patch=False)\n",
        "val_set = DroneDataset(x_val_dir, y_val_dir, mean, std, t_val, patch=False)\n",
        "\n",
        "#dataloader\n",
        "batch_size= 3 \n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=2, shuffle=False)               "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ-ZypiFJSgJ",
        "papermill": {
          "duration": 0.029797,
          "end_time": "2021-02-18T10:06:31.864199",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.834402",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:31.930374Z",
          "iopub.status.busy": "2021-02-18T10:06:31.929553Z",
          "iopub.status.idle": "2021-02-18T10:06:32.532256Z",
          "shell.execute_reply": "2021-02-18T10:06:32.531700Z"
        },
        "id": "ZXb8nBmpJSgK",
        "papermill": {
          "duration": 0.637787,
          "end_time": "2021-02-18T10:06:32.532384",
          "exception": false,
          "start_time": "2021-02-18T10:06:31.894597",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = smp.Unet('mobilenet_v2', encoder_weights='imagenet', classes=23, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-02-18T10:06:32.604280Z",
          "iopub.status.busy": "2021-02-18T10:06:32.602994Z",
          "iopub.status.idle": "2021-02-18T10:06:32.606962Z",
          "shell.execute_reply": "2021-02-18T10:06:32.607359Z"
        },
        "id": "32nY_jBWJSgN",
        "papermill": {
          "duration": 0.043393,
          "end_time": "2021-02-18T10:06:32.607492",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.564099",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncudHa0UJSgQ",
        "papermill": {
          "duration": 0.031715,
          "end_time": "2021-02-18T10:06:32.670851",
          "exception": false,
          "start_time": "2021-02-18T10:06:32.639136",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch.utils as smp_utils\n",
        "DEVICE = 'cuda'\n",
        "\n",
        "loss = smp_utils.losses.DiceLoss()\n",
        "metrics = [\n",
        "    smp_utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.0001),\n",
        "])\n",
        "\n",
        "# create epoch runners \n",
        "# it is a simple loop of iterating over dataloader`s samples\n",
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "J6B-SwJ_sCqu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_score = 0\n",
        "\n",
        "for i in range(0, 40):\n",
        "    \n",
        "    print('\\nEpoch: {}'.format(i))\n",
        "    train_logs = train_epoch.run(train_loader)\n",
        "    valid_logs = valid_epoch.run(val_loader)\n",
        "    \n",
        "    # do something (save model, change lr, etc.)\n",
        "    if max_score < valid_logs['iou_score']: #scoatem validarea ca nu merge, rezolvam mai tarziu\n",
        "        max_score = valid_logs['iou_score']\n",
        "        torch.save(model, './best_model.pth')\n",
        "        print('Model saved!')\n",
        "        \n",
        "    if i == 25:\n",
        "        optimizer.param_groups[0]['lr'] = 1e-5\n",
        "        print('Decrease decoder learning rate to 1e-5!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "sdQpvKlusV__",
        "outputId": "28edc81e-675d-42bf-917f-6daf43c1c86f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "train:   0%|          | 0/32 [00:09<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2117b0fdf0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvalid_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/segmentation_models_pytorch/utils/train.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# update loss logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/segmentation_models_pytorch/utils/train.py\u001b[0m in \u001b[0;36mbatch_update\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/segmentation_models_pytorch/utils/losses.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y_pr, y_gt)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0my_pr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         return 1 - F.f_score(\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0my_pr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0my_gt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/segmentation_models_pytorch/utils/functional.py\u001b[0m in \u001b[0;36mf_score\u001b[0;34m(pr, gt, beta, eps, threshold, ignore_channels)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (23) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ZfzV8FjtcI9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3976.886777,
      "end_time": "2021-02-18T11:12:15.631556",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2021-02-18T10:05:58.744779",
      "version": "2.2.2"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}